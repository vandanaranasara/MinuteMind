import os
import logging
from dotenv import load_dotenv
import json

load_dotenv()
logger = logging.getLogger("llm_client")

import google.generativeai as genai


class LLMClient:
    """
    Wrapper for Google Gemini.
    If no GOOGLE_API_KEY is found, returns stub JSON instead.
    """

    def __init__(self):
        self.api_key = os.getenv("GOOGLE_API_KEY", "")
        # Use the working Gemini model from your chatbot
        # self.model = os.getenv("LLM_MODEL", "gemini-2.5-pro")
        self.model = os.getenv("LLM_MODEL", "gemini-2.5-flash")

        if self.api_key:
            try:
                genai.configure(api_key=self.api_key)
                self.enabled = True
                logger.info("Configured google.generativeai client")
            except Exception as e:
                logger.error("Failed to configure google.generativeai: %s", e)
                self.enabled = False
        else:
            self.enabled = False

    def complete(self, prompt: str) -> str:
        if self.enabled:
            try:
                model = genai.GenerativeModel(self.model)
                resp = model.generate_content(prompt)

                # Return text safely
                if hasattr(resp, "text") and resp.text:
                    return resp.text
                # fallback for newer response structures
                if hasattr(resp, "result"):
                    return resp.result[0].content[0].text
                return str(resp)
            except Exception as e:
                logger.error("Error calling Gemini model: %s", e)
                return "Error: Could not generate response."

        # -------- Stub mode --------
        logger.info("LLMClient running in stub mode (no API key). Returning sample JSON.")
        sample = {
            "summary_short": [
                "Topic overview and purpose",
                "Key decision made",
                "Assigned action items",
                "Risks and blockers",
                "Next meeting/time"
            ],
            "summary_detailed": "This is a sample detailed summary generated by stub LLM.",
            "discussion_flow": ["Intro by PM", "Requirements discussion", "Task assignment", "Wrap-up"],
            "timeline": [
                {"timestamp": "00:02", "topic": "Introductions"},
                {"timestamp": "00:10", "topic": "Requirements & scope"}
            ],
            "action_items": [
                {"task": "Create project plan", "assigned_to": "Alice", "deadline": "2025-12-10"}
            ],
            "speaker_sentiment": {
                "Alice": "positive",
                "Bob": "neutral"
            }
        }
        return json.dumps(sample)


